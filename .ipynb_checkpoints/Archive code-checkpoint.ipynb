{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSY 6500 Project\n",
    "\n",
    "## Authors: Taylor Feagin, Sarah Gaines\n",
    "\n",
    "### Uses Billboard 200 data and Spotify Acoustic feature data\n",
    "\n",
    "Dataset Content and download: https://www.kaggle.com/snapcrack/the-billboard-200-acoustic-data/\n",
    "\n",
    "Data Columns Explanation for acoustic_features table: https://www.kaggle.com/nadintamer/top-tracks-of-2017#featuresdf.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/50996820/how-to-import-a-sqlite3-database-into-python-jupyter-notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taylor's path\n",
    "cnx = sqlite3.connect(r'C:\\\\Users\\\\tbfea\\\\OneDrive\\\\Documents\\\\GitHub\\\\INSY6500Project\\\\Project\\\\billboard-200.db')\n",
    "\n",
    "# Sarah's path\n",
    "# cnx = sqlite3.connect(r'C:\\\\Users\\\\slgai\\\\Documents\\\\GitHub\\\\billboard_200.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/50996820/how-to-import-a-sqlite3-database-into-python-jupyter-notebook\n",
    "\n",
    "albums = pd.read_sql_query(\"SELECT * FROM albums\", cnx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/50996820/how-to-import-a-sqlite3-database-into-python-jupyter-notebook\n",
    "\n",
    "feat = pd.read_sql_query(\"SELECT * FROM acoustic_features\", cnx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new dataframe with just the columns album and rank from 'albums' \n",
    "\n",
    "albumrank = albums[['album', 'rank']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges the album rank dataframe with the features dataframe, basically adds the rank to the features database.\n",
    "# issue: has duplicates of the song features\n",
    "fulldata = pd.merge(albumrank, feat, how = \"outer\")\n",
    "# all albums that were number one each week using the full data dataframe\n",
    "num1full = fulldata[fulldata['rank'] == '1'].copy()\n",
    "# data frame of the average acoustic characteristics for each album in num1full\n",
    "avg_feat = num1full.groupby('album')[['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveness','loudness','mode','speechiness','tempo','time_signature','valence']].aggregate('mean')\n",
    "# https://stackoverflow.com/questions/13411544/delete-column-from-pandas-dataframe\n",
    "# deletes id column of num1full to perform merge\n",
    "del num1full['id']\n",
    "# https://stackoverflow.com/questions/53645882/pandas-merging-101\n",
    "# left2.merge(right2, left_on='keyLeft', right_on='keyRight', how='inner')\n",
    "#merges num1full with freqgt1 and drops missing values. Gets full data for albums who were number 1 for more than 1 week\n",
    "df = freqgt1.merge(num1full, left_on = 'album', right_on = 'album', how = \"outer\")\n",
    "df = df.dropna()\n",
    "df = df.dropna(axis='columns')\n",
    "#drops duplicates \n",
    "dfunique = df.copy()\n",
    "dfunique.drop_duplicates(subset =\"album\", \n",
    "                     keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows albums with number 1 rank from albums dataframe\n",
    "num1 = albums[albums['rank'] == '1'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops the duplicates in the num 1 dataframe \n",
    "# https://www.geeksforgeeks.org/python-pandas-dataframe-drop_duplicates/\n",
    "num1unique = num1.copy()\n",
    "num1unique.drop_duplicates(subset =\"album\", \n",
    "                     keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletes date column of feat as it is not needed\n",
    "del feat['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of weeks each album was number one \n",
    "freq1 = num1.groupby(['artist','album'])[['id']].count()\n",
    "freq1.head()\n",
    "# histogram of number of weeks albums were number one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency greater than 1; albums that were number 1 for more than one week\n",
    "freqgt1 = freq1[freq1['id']>1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarah added - new dataframe with average acoustic feat per album\n",
    "feat_uni = (feat.groupby('album')[['acousticness','danceability','duration_ms','energy','instrumentalness','key','liveness','loudness','mode','speechiness','tempo','time_signature','valence']].aggregate('mean')).reset_index()\n",
    "feat_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#merges freq 1 with feat_uni to get the average unique features of the albums who have been number 1\n",
    "# Sarah added - \n",
    "testdf = freq1.merge(feat_uni, left_on = 'album', right_on = 'album', how = \"outer\")\n",
    "testdf = testdf.dropna()\n",
    "testdf = testdf.dropna(axis='columns')\n",
    "# testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sarah added\n",
    "# testdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export dataframe to a csv to use in R\n",
    "# https://datatofish.com/export-dataframe-to-csv/\n",
    "#Sarah's path\n",
    "# testdf.to_csv(r'C:\\Users\\slgai\\Documents\\GitHub\\6500project\\UniqueAlbumFeat.csv')\n",
    "\n",
    "#Taylor's path\n",
    "testdf.to_csv(r'C:\\Users\\tbfea\\OneDrive\\Documents\\GitHub\\6500project\\UniqueAlbumFeat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
